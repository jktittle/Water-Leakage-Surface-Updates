{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to Update Hydraulic Grade Values and Interpolate Sample Points Using Ordinary Kriging\n",
    "\n",
    "### Introduction\n",
    "\n",
    "The Python component of this project was used to automate daily data imports and maintenance required to dependably produce leakage area results. Since the project is applied to a real-world water distribution system, data was generated daily, creating the need to automate labor intensive tasks. To do this, the pandas and geopandas python libraries were used to handle most of the data management by performing data imports, data cleanup, data table merges, and hydraulic grade calculations. This was accomplished by importing regularly generated pressure information into pandas data frames and hydrant locational information into a geopandas spatially enabled geodataframes. \n",
    "\n",
    "The static pressure update processing is an ongoing program at the water department, so an automated script was developed to capture additional hydrant pressure tests daily. This placed information indicating large areas exhibiting water leakage in front of decision-makers in a timely manner so that large water breaks can be identified and repaired. The script was written in Python and developed using Jupyter Notebooks in conjunction with ArcGIS to document each step and support replication in other water systems. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the following python libraries\n",
    "import sys, os, csv, fiona, datetime, arcpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "from arcpy import env\n",
    "from arcpy.sa import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the environment workspace and overwrite settings\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.workspace = \"C:\\\\StaticPressureProcess\\\\StaticPressureData.gdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create variables for the pressure update csv, pressure test point file, and pressure zone polygon file\n",
    "pressureUpdateFile = \"C:\\\\StaticPressureProcess\\\\TasksExport.csv\"\n",
    "pressurePoint = \"C:\\\\StaticPressureProcess\\\\StaticPressureData.gdb\\\\PZ1838A_PressureTestPnts\"\n",
    "pressureZone = \"C:\\\\StaticPressureProcess\\\\StaticPressureData.gdb\\\\PZ1838A_Redefined\"\n",
    "outRaster = \"C:\\\\StaticPressureProcess\\\\StaticPressureData.gdb\\\\LeakSurface_\" + datetime.date.today().strftime(\"%m%d%Y\")\n",
    "geoStatModel = \"C:\\\\StaticPressureProcess\\\\OrdinaryKrigingModel_1838A_TheBest.xml\"\n",
    "geoStatLayer = \"KrigingOutLayer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the fiona library to list all layers within the StaticPressureData geodatabase. \n",
    "#The list will be used to reference the layer imported with geopandas\n",
    "fiona.listlayers(\"C:\\\\StaticPressureProcess\\\\StaticPressureData.gdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the PZ1838_PressureTestPnts feature class as a geodataframe.\n",
    "#The layer parameter is taken from the fiona generated list position of the desired geodatabase feature class.\n",
    "testSites = gp.read_file(\"C:\\\\StaticPressureProcess\\\\StaticPressureData.gdb\",driver='FileGDB', layer=3)\n",
    "testSites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the DateCollected column\n",
    "testSites['DateCollected']=pd.to_datetime(testSites['DateCollected'])\n",
    "testSites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the pressure updates csv into a pandas data frame\n",
    "staticUpdates = gp.read_file( \"C:\\\\StaticPressureProcess\\\\TasksExport.csv\")\n",
    "staticUpdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Add the FACILITYID column and slice the text to only contain hydrant identifiers\n",
    "staticUpdates['FACILITYID'] = staticUpdates.Asset.str[14:]\n",
    "\n",
    "#Replace spaces with underscores\n",
    "staticUpdates.columns = staticUpdates.columns.str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
    "\n",
    "#Convert the Static_Pressure column to numericvalues\n",
    "staticUpdates['Static_Pressure']=pd.to_numeric(staticUpdates.Static_Pressure)\n",
    "staticUpdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the Actual_Stop_Date column\n",
    "staticUpdates['Actual_Stop_Date']=pd.to_datetime(staticUpdates['Actual_Stop_Date'])\n",
    "staticUpdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find and remove all rows with a Static_Pressure value equal to zero\n",
    "zeroStaticP = staticUpdates[ staticUpdates['Static_Pressure'] == 0 ].index\n",
    "staticUpdates.drop(zeroStaticP , inplace=True)\n",
    "\n",
    "#Find and remove all rows with a Static_Pressure value greater than 200\n",
    "zeroStaticP = staticUpdates[ staticUpdates['Static_Pressure'] > 300 ].index\n",
    "staticUpdates.drop(zeroStaticP , inplace=True)\n",
    "\n",
    "staticUpdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join the staticUpdates data frame to the testSites data frame using the FACILITYID field\n",
    "#This creates a new data frame that contains the static pressure updates to apply to the 1838A test hydrants\n",
    "mergedPressureInfo = testSites.merge(staticUpdates, on='FACILITYID')\n",
    "mergedPressureInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update new StaticPressure column\n",
    "mergedPressureInfo.StaticPressure = mergedPressureInfo.Static_Pressure\n",
    "\n",
    "#Recalculate the Hydrograde column\n",
    "mergedPressureInfo.HydroGrade = mergedPressureInfo.Elevation + 2.31 * mergedPressureInfo.StaticPressure\n",
    "\n",
    "#Update the DateCollected column with new dates from the Actual_Stop_Date column\n",
    "mergedPressureInfo.DateCollected = mergedPressureInfo.Actual_Stop_Date\n",
    "mergedPressureInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove unneeded fields from the data frame\n",
    "del mergedPressureInfo['Task_ID']\n",
    "del mergedPressureInfo['Asset']\n",
    "del mergedPressureInfo['Activity']\n",
    "del mergedPressureInfo['Static_Pressure']\n",
    "del mergedPressureInfo['Actual_Stop_Date']\n",
    "del mergedPressureInfo['geometry_y']\n",
    "\n",
    "#Rename the geometry column\n",
    "mergedPressureInfo.rename(columns={\"geometry_x\":\"geometry\"}, inplace=True)\n",
    "mergedPressureInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicate values\n",
    "mergedPressureInfo = mergedPressureInfo.sort_values('DateCollected',ascending=True)\n",
    "mergedPressureInfo = mergedPressureInfo.drop_duplicates(subset='FACILITYID', keep='first')\n",
    "mergedPressureInfo = mergedPressureInfo.sort_values('FACILITYID',ascending=True)\n",
    "mergedPressureInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update testSite values with the new static pressure test values and export to a shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the testSites index to the FACILITYID column\n",
    "testSites = testSites.set_index('FACILITYID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the mergedPressureInfo data frame index to the FACILITYID column\n",
    "mergedPressureInfo = mergedPressureInfo.set_index('FACILITYID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedPressureInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the update function on the testSites data frame\n",
    "testSites.update(mergedPressureInfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset the indexes\n",
    "testSites.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testSites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the merged data frame to a GeoDataFrame and remove null HydroGrade Values\n",
    "updatedGdf = gp.GeoDataFrame(testSites, geometry='geometry')\n",
    "NewGdf = updatedGdf[updatedGdf.HydroGrade.notnull()]\n",
    "NewGdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the DateCollected column to string values in order to export to shapefile\n",
    "NewGdf['DateCollected']=NewGdf['DateCollected'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the new geodataframe's projection and plot the new pressure tests within 1838A\n",
    "NewGdf.crs = {\"init\":\"epsg:2274\"}\n",
    "updatedGdf.plot(figsize=(12,12));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create new shapefile name and export the geodataframe to new shapefile\n",
    "shpFileName = r\"C:\\StaticPressureProcess\\UpdatedStaticPressureTests_\" + datetime.date.today().strftime(\"%m%d%Y\") + \".shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewGdf.to_file(shpFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the ordinary kriging model on the updated hydrant pressure points\n",
    "\n",
    "Run the Kriging interpolation using the pressure point layer. This step creates a Geostatistical Layer using tools from Geostatistical Analyst. The tool uses an existing Geostatistial layer as a model source to duplicate its parameters and should be stored in the project workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check out the ESRI Spatial and Geostatistical Analyst Extensions\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "arcpy.CheckOutExtension(\"GeoStats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "krigingInLayer = \"C:\\\\StaticPressureProcess\\\\UpdatedStaticPressureTests_07192019.shp X=Shape Y=Shape F1=HydroGrade\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arcpy.GACreateGeostatisticalLayer_ga(in_ga_model_source, in_datasets, out_layer)\n",
    "arcpy.GACreateGeostatisticalLayer_ga(geoStatModel, krigingInLayer, geoStatLayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the pressure surface based on pressurePoints\n",
    "arcpy.Kriging_3d(shpFileName, \"HydroGrade\", outRaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clip the interpolation surface to the desired polygon boundary layer\n",
    "arcpy.Clip_analysis(outRaster, pressureZone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check back in the ESRI Spatial and Geostatistical Analyst Extensions\n",
    "arcpy.CheckInExtension(\"Spatial\")\n",
    "arcpy.CheckInExtension(\"GeoStats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Completed Script\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
